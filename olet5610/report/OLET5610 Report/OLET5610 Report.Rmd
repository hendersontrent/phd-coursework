---
title: OLET5610 Report
authors:
  - name: Trent Henderson
    email: then6675@uni.sydney.edu.au
bibliography: references.bib
biblio-style: unsrt
output: 
  rticles::arxiv_article:
    keep_tex: true
---

# Method

XX

## Participants

XX

## Materials

XX

## Procedure

XX

```{r, echo = FALSE, warning = FALSE, message = FALSE}
# Load packages

library(dplyr)
library(tidyr)
library(ggplot2)
library(theft)
library(foreign)
library(factoextra)
library(ggpubr)
library(broom)

#-------- Pull the dataset ---------

#' Function to load and process files into a single tidy dataframe
#' @param problem string specifying the problem to use
#' @return an object of class dataframe
#' @author Trent Henderson
#' 

tidy_arff_file <- function(problem){
  
  # Pull the dataset
  
  temp <- tempfile()
  download.file(paste0("https://www.timeseriesclassification.com/Downloads/", problem, ".zip"), temp, mode = "wb")
  
  #-----------------------------
  # Grab the train and test data
  #-----------------------------
  
  train <- foreign::read.arff(unz(temp, paste0(problem, "_TRAIN.arff"))) %>%
    mutate(id = row_number()) %>%
    mutate(set_split = "Train")
  
  themax <- max(train$id) # To add in test set to avoid duplicate IDs
  
  test <- foreign::read.arff(unz(temp, paste0(problem, "_TEST.arff"))) %>%
    mutate(id = row_number() + themax) %>% # Adjust relative to train set to stop double-ups
    mutate(set_split = "Test")
  
  #----------------------------
  # Wrangle data to long format
  #----------------------------
  
  # Train
  
  thecolstr <- colnames(train)
  keepcolstr <- thecolstr[!thecolstr %in% c("target", "id", "set_split")]
  
  train <- train %>%
    pivot_longer(cols = all_of(keepcolstr), names_to = "timepoint", values_to = "values") %>%
    mutate(timepoint = as.numeric(gsub(".*?([0-9]+).*", "\\1", timepoint)))
  
  # Test
  
  thecolste <- colnames(test)
  keepcolste <- thecolste[!thecolste %in% c("target", "id", "set_split")]
  
  test <- test %>%
    pivot_longer(cols = all_of(keepcolste), names_to = "timepoint", values_to = "values") %>%
    mutate(timepoint = as.numeric(gsub(".*?([0-9]+).*", "\\1", timepoint)))
  
  #------
  # Merge
  #------
  
  outs <- bind_rows(train, test)
  return(outs)
}

tmp <- tidy_arff_file(problem = "Chinatown")

#-------- Calculate features ---------

# Fix Python environment to where the Python libraries are installed on my machine

init_theft("~/opt/anaconda3/bin/python")

# Extract time-series features

outs <- calculate_features(tmp, id_var = "id", time_var = "timepoint", 
                           values_var = "values", group_var = "target", 
                           feature_set = c("catch22", "tsfresh", "TSFEL", "Kats"), 
                           catch24 = TRUE, tsfresh_cleanup = FALSE, seed = 123)

# Get feature matrix size to highlight dimensionality

#print(paste0(length(unique(outs$id)), " x ", length(unique(outs$names))))
```

# Results

XX

## Dimensionality reduction

XX

See Figure \@ref(fig:eigenplots)).

```{r eigenplots, fig.cap = "Summary of nineteen retained rincipal components. (A) Percentage of variance explained is plotted in descending order for each of the retained principal components. (B) Cumulative variance explained is plotted for each of the retained principal components. An 80% cumulative variance threshold was selected to determine the principal components to retain which returned the nineteen plotted here (from the original 313). (C) Eigenvalues of the nineteen retained principal components are plotted in descending order. All retained components exceed the $\lambda = 1$ cutoff for the Kaiser criterion.", echo = FALSE, warning = FALSE, message = FALSE}
#-------
# Do PCA
#-------

# Widen model matrix and fit PCA

mywhere <- function(fn) {
  predicate <- rlang::as_function(fn)
  
  function(x, ...) {
    out <- predicate(x, ...)
    if (!rlang::is_bool(out)) {
      rlang::abort("`where()` must be used with functions that return `TRUE` or `FALSE`.")
    }
    out
  }
}

fits <- outs %>%
  dplyr::select(id, names, values) %>%
  tidyr::pivot_wider(id_cols = "id", names_from = "names", values_from = "values") %>%
  tibble::column_to_rownames(var = "id") %>%
  dplyr::select_if(~sum(!is.na(.)) > 0) %>% # Remove features that are just NA before dropping rows
  tidyr::drop_na() %>%
  dplyr::select(mywhere(~dplyr::n_distinct(.) > 1)) # Keep columns that aren't a constant

# Get feature matrix size to highlight dimensionality

print(paste0(nrow(fits), " x ", ncol(fits)))

# Fit PCA

fits <- fits %>%
  stats::prcomp(scale = TRUE)

#------------------------
# Assess # of PCs to keep
#------------------------

# Filter to just PCs that contribute just over 80% of the variance

eigs <- as.data.frame(get_eig(fits)) %>%
  tibble::rownames_to_column(var = "dimension") %>%
  mutate(rank = dense_rank(cumulative.variance.percent),
         flag = ifelse(cumulative.variance.percent > 80, TRUE, FALSE)) %>%
  group_by(flag) %>%
  mutate(ranker = dense_rank(cumulative.variance.percent)) %>%
  ungroup() %>%
  mutate(ranker = ifelse(flag == FALSE, 1, ranker)) %>%
  filter(ranker == 1) %>%
  dplyr::select(-c(rank, flag, ranker)) %>%
  mutate(dimension = gsub("Dim.", "\\1", dimension),
         dimension = paste0("PC ", dimension))

# Draw % of variance explained plot

p <- eigs %>%
  ggplot(aes(x = reorder(dimension, -variance.percent), y = variance.percent)) +
  geom_bar(stat = "identity", fill = "#1B9E77") +
  geom_line(group = 1, size = 1) +
  geom_point(size = 2) +
  labs(title = "(A) Percentage of variance explained by retained principal component",
       x = "Principal component",
       y = "Variance explained (%)") +
  geom_line() +
  geom_point() +
  scale_y_continuous(limits = c(0, 35),
                     breaks = seq(from = 0, to = 40, by = 5),
                     labels = function(x)paste(x, "%")) +
  theme_bw() +
  theme(panel.grid.minor = element_blank(),
        plot.title = element_text(face = "bold"))

# Draw cumulative variance plot

p1 <- eigs %>%
  ggplot(aes(x = reorder(dimension, cumulative.variance.percent), y = cumulative.variance.percent)) +
  geom_bar(stat = "identity", fill = "#D95F02") +
  geom_line(group = 1, size = 1) +
  geom_point(size = 2) +
  geom_hline(yintercept = 80, lty = "dashed", colour = "black", size = 1) +
  labs(title = "(B) Cumulative variance explained by retained principal components",
       x = "Principal component",
       y = "Cumulative variance explained (%)") +
  scale_y_continuous(limits = c(0, 100),
                     breaks = seq(from = 0, to = 100, by = 20),
                     labels = function(x)paste(x, "%")) +
  theme_bw() +
  theme(panel.grid.minor = element_blank(),
        plot.title = element_text(face = "bold"))

# Draw eigenvalue plot

p2 <- eigs %>%
  ggplot(aes(x = reorder(dimension, -eigenvalue), y = eigenvalue)) +
  geom_bar(stat = "identity", fill = "#7570B3") +
  geom_hline(yintercept = 1, lty = "dashed", colour = "black", size = 1) +
  labs(title = "(C) Eigenvalues of retained principal components",
       x = "Principal component",
       y = "Eigenvalue") +
  theme_bw() +
  theme(panel.grid.minor = element_blank(),
        plot.title = element_text(face = "bold"))

# Combine plots

eigenplots <- ggpubr::ggarrange(p, p1, p2, nrow = 3, ncol = 1, common.legend = TRUE, legend = "bottom")
print(eigenplots)
```

XX

See Figure \@ref(fig:biplot)).

```{r biplot, fig.cap = "Principal components analysis biplot. The first principal component (positioned along the $x$-axis) explains 30.5% of the variance in the Chinatown dataset. The second principal component (positioned along the $y$-axis) explains 17.1% of the variance in the Chinatown dataset. Despite some overlap, meaningful class separation is visible between the $Weekend$ and $Weekday$ classes.", echo = FALSE, warning = FALSE, message = FALSE}
# Get eigenvalues and summary stats for plot

eigen_summary <- fits %>%
  broom::tidy(matrix = "eigenvalues") %>%
  dplyr::filter(.data$PC %in% c(1, 2)) %>% # Filter to just the 2 going in the plot
  dplyr::select(c(.data$PC, .data$percent)) %>%
  dplyr::mutate(percent = round(.data$percent * 100), digits = 1)

eigen_pc1 <- eigen_summary %>%
  dplyr::filter(.data$PC == 1)

eigen_pc2 <- eigen_summary %>%
  dplyr::filter(.data$PC == 2)

eigen_pc1 <- paste0(eigen_pc1$percent,"%")
eigen_pc2 <- paste0(eigen_pc2$percent,"%")

# Get group data

groups <- outs %>%
  dplyr::rename(group_id = group) %>%
  dplyr::group_by(.data$id, .data$group_id) %>%
  dplyr::summarise(counter = dplyr::n()) %>%
  dplyr::ungroup() %>%
  dplyr::select(-c(.data$counter)) %>%
  dplyr::mutate(id = as.factor(.data$id)) %>%
  dplyr::mutate(group_id = ifelse(.data$group_id == "1", "Weekend", "Weekday")) %>%
  dplyr::mutate(group_id = factor(.data$group_id, levels = c("Weekend", "Weekday")))

# Draw plot

pca_plot <- fits %>%
  broom::augment(fit_mat) %>%
  dplyr::rename(id = 1) %>%
  dplyr::mutate(id = as.factor(.data$id)) %>%
  dplyr::rename(.fitted1 = .data$.fittedPC1,
                .fitted2 = .data$.fittedPC2) %>%
  dplyr::inner_join(groups, by = c("id" = "id")) %>%
  dplyr::mutate(group_id = as.factor(.data$group_id)) %>%
  ggplot2::ggplot(ggplot2::aes(x = .data$.fitted1, y = .data$.fitted2)) +
  ggplot2::stat_ellipse(ggplot2::aes(x = .data$.fitted1, y = .data$.fitted2, fill = .data$group_id), geom = "polygon", alpha = 0.2) +
  ggplot2::guides(fill = "none") +
  ggplot2::scale_fill_brewer(palette = "Dark2") +
  ggplot2::geom_point(size = 2, ggplot2::aes(colour = .data$group_id)) + 
  ggplot2::labs(title = "Principal components analysis biplot",
                x = paste0("PC 1"," (", eigen_pc1, ")"),
                y = paste0("PC 2"," (", eigen_pc2, ")"),
                colour = NULL) +
  ggplot2::scale_colour_brewer(palette = "Dark2") +
  ggplot2::theme_bw() +
  ggplot2::theme(panel.grid.minor = ggplot2::element_blank(),
                 legend.position = "bottom",
                 plot.title = element_text(face = "bold"))

print(pca_plot)
```

XX

## Time-series classification

XX

```{r, echo = FALSE, warning = FALSE, message = FALSE}

```
