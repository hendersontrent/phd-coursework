---
title: "Reproducibility Essay"
author: "Trent Henderson"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

The work of Renner et al. (2018)^[Renner F, Kersbergen I, Field M, Werthmann J. Dutch courage? Effects of acute alcohol consumption on self-ratings and observer ratings of foreign language skills. J Psychopharmacol. 2018 Jan;32(1):116-122. doi: 10.1177/0269881117735687. Epub 2017 Oct 18. PMID: 29043911.] sought to investigate the effects of acute alcohol consumption on self-ratings and the ratings of observers on foreign language skills. This essay discusses aspects of the study that would make it more possible to conduct a replication study.

The methods section of the study had failed to report the following, which would inhibit the conduction of a replication study:

* Poster materials for participant recruitment were not provided (p. 117) which may limit a replication study's ability to recruit a similar sample
* The exact instrumental music that participants listened to after consumption of the drink for fifteen minutes prior to the language task was not shared (p. 119), so an exact replication could not be performed from reading this article alone
* The location of the study was described as a "laboratory visually resembling a pub" (p. 119) but no visual evidence (i.e., photograph)
* The list of thirteen arithmetic problems were not supplied (p. 118), meaning an exact replication cannot be conducted
* Experimenter scripts were not provided, meaning the process of welcoming the participant, providing written and verbal information about the study, and the offering of the drink (p. 119) cannot be replicated exactly
* Instructions to observers who were rating the audio recordings were not supplied (p. 118) making an exact replication difficult
* The list of standardized questions for cases when participants needed less time (p. 118) were not supplied

In addition to the points above, there are other aspects of reproducibility worth discussing. Importantly, the article did not provide open access to the data nor code used for analysis. This limits the ability for other researchers to engage in computational reproducibility of the results and raises questions about the transparency of the study. Moreover, However, despite this criticism, there were elements of reproducibility that this article excelled at. The study blinded participants to the experimental condition (low dose of alcohol or control beverage with no alcohol) they were assigned to, and both the experimenter who conducted the study with them and the two native Dutch speakers who conducted observer ratings were also condition-blind. Blinding is critical to this study for several reasons: (i) blinding of participants mitigates *the placebo effect*, whereby un-blinded participants' expectations affect what they report (essential when self-ratings are a method of measurement); (ii) blinding of the experimenter who runs the experiment with participants is crucial because knowledge of the manipulation condition may (consciously or unconsciously) make them react differently to participants based on condition (e.g., encourage participants that their Dutch skills are strong, resulting in a self-fulfilling prophecy), thus introducing a source of bias; and (iii) blinding of observers is important because knowledge of the manipulation condition may influence their perceptions and introduce bias in their scoring. The study also does not appear to have engaged in hypothesising-after-results-are-known (HARKing). The authors specify a discrete set of four hypotheses (p. 117), each grounded in previous research and sensible real-world beliefs (such as Hypothesis 1 which posited that those who consumed alcohol would rate their performance higher). Further, not all the results for the hypotheses returned statistically significant results. The lack of exceedingly favourable results makes it unlikely that the authors engaged in HARKing or even *p*-hacking more broadly.
