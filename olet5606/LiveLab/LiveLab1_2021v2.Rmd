---
title: "Data Wrangling - Live Lab 1"
subtitle: "NYC Water Quality"
author: "University of Sydney 2021"
output:
  html_document:
    theme: flatly
    number_sections: yes
    self_contained: yes
    toc: true
    toc_float: false
    toc_depth: 3
    code_folding: hide
---

```{r setup, include=FALSE}
# Code Chunk Option
knitr::opts_chunk$set(warning = FALSE, # in general don't do this!
                      fig.align = "center",
                      fig.retina = 4)

# Reduce scientific Notation
options(scipen = 5)
```


# Overview

## RStudio Workspace

## Contents of a Rmarkdown {`.Rmd`}

## Knitting a document

 - Knitting
 - Preview in Viewer Pane


# Setup 


## Loading Packages

1. ONLY ONCE -- Install Package

  - Type:  `install.packages("put_package_name_here")` into the console
  - e.g. `install.packages("tidyverse")`


2. EVERY TIME YOU WANT TO USE -- Load Package

  - Type: `library("put_package_name_here")` into your code chunk
  - e.g. `library("tidyverse")`
 
```{r, message = F}
# Load Relevant Packages
library(tidyverse) # piping `%>%`, plotting, reading data
library(skimr) # exploratory data summary
library(naniar) # exploratory plots
library(kableExtra) # tables
library(lubridate) # for date variables
library(plotly)

# Extension
  # Try to save time by installing a package to install packages!
  # install.packages("pacman")
  # pacman::p_load(tidyverse, skimr, naniar, kableExtra, lubridate, plotly)
```

## Loading Data

**If the data is online:**

This is easy for datasets that are not too large & already hosted online!

**If the data is a local file:**


1. File Management

 - In general, put your data file in the same folder as your R file.

2. Setting working directory

 - *If you are knitting your document*: it will automatically look for data in the same folder as your R file. So you should have no dramas (per step 1.).

 - *If you are running a section of code*: you will need to specify which folder the data is in. The best way to do this is by following these menu options: `Session Menu >> Set Working Directory >> To Source File Location`.

3. Load Data

 - Read data using the `read_csv()` function which comes from the `tidyverse` package.


```{r, message = F }
# Load Data
data = read_csv("https://www.maths.usyd.edu.au/u/UG/OL/OLEO5605/r/NYC_Drinking_Water.csv")
#data = read_csv("Drinking_Water_Quality_Distribution_Monitoring_Data.csv")
```



# Exploratory Data Analysis

## Quick Snapshot

```{r}
# Glimpse Function [From tidyverse package]
data %>% glimpse()

# Skim Function [From skimr package]
data %>% skim()

# Summary Function [From base package -- preinstalled!]
data %>% summary()
```


## Exploring missingness

```{r}
# vis_miss function [From visdat or naniar packages]
vis_miss(data, warn_large_data = FALSE)
```

## Exploring numeric variables

 - What do you notice about outliers & skewness?

```{r}
data %>%
  select(where(is.numeric)) %>%
  pivot_longer(everything(),
               names_to = "Variable",
               values_to = "Value") %>%
  group_by(Variable) %>%
  summarise(Mean = mean(Value, na.rm = TRUE),
            Median = median(Value, na.rm = TRUE)) %>%
  kable() %>% # putting into a table
  kable_styling(bootstrap_options = c("hover")) # making table look good
```

```{r}
p = data %>%  
  select(where(is.numeric)) %>%
  pivot_longer(everything(), 
               names_to = "Variable", 
               values_to = "Value") %>% 
  filter(!is.na(Value)) %>%
  ggplot(aes(x = Value)) +
  facet_wrap(~ Variable, scales = "free_y") +
  geom_histogram(bins = 30, fill = "lightblue", color = "darkblue") +
  labs(y = "Frequency") +
  theme_bw()

ggplotly(p)
```

```{r}
p = data %>%  
  select(where(is.numeric)) %>%
  pivot_longer(everything(), 
               names_to = "Variable", 
               values_to = "Value") %>% 
  filter(!is.na(Value)) %>%
  ggplot(aes(y = Value)) +
  facet_wrap(~ Variable, scales = "free_y") +
  geom_boxplot(fill = "lightblue", color = "darkblue") +
  theme_bw() +
  theme(strip.text.x = element_text(size = 8))

p
```

# Data Cleaning

```{r}
# See what state things are currently in
data %>% glimpse()
```

```{r}
# Data Cleaning

## Changing type of `Sample Date`
  # Note: mdy from [From tidyverse package]
data = data %>% 
  mutate(`Sample Date` = mdy(`Sample Date`))

# Adding additional time columns
data = data %>% 
        mutate(`Week of Year` = week(`Sample Date`),  
               `Weekday` = wday(`Sample Date`), 
               `Month Number` = month(`Sample Date`),
               `Hour` = hour(`Sample Time`))

# Giving Month Name an Order
data = data %>% 
  mutate(`Month` = factor(month.name[`Month Number`], 
                          levels = month.name))

# Converting Categorical Variables to Factors
data = data %>% 
  mutate(across(where(is_character) & !c(Location, `Sample Site`), 
         as_factor))

# Drop NA -- Q: Do you think this is appropriate?
# data = data %>%
#   drop_na()
```

```{r}
# Check we're happy with cleaned data
data %>% glimpse()
data %>% summary()
```

# Interrogating the data

## Which date had the highest Turbidity reading?

```{r}
top_10_turbidity = data %>% 
  arrange(desc(`Turbidity (NTU)`)) %>% 
  select(`Sample Date`, `Turbidity (NTU)`) %>%
  head(10)

top_10_turbidity %>%
  kable(caption = "Top 10 Turbidity readings") %>%
  kable_styling(bootstrap_options = c("hover"))
```

The highest Turbidity rating was on `r (top_10_turbidity[[1]][1])` with a reading of `r top_10_turbidity[[2]][1]`.




## Is there a difference between the median readings for Turbidity, Chlorine, and Fluoride for the different types of sample sites?

```{r}
class_medians = data %>% 
  group_by(`Sample class`) %>%
  summarise(med_chlorine = median(`Residual Free Chlorine (mg/L)`, na.rm = TRUE),
            med_turbidity = median(`Turbidity (NTU)`, na.rm = TRUE),
            med_flouride = median(`Fluoride (mg/L)`, na.rm = TRUE)) 

class_medians %>%
  kable() %>%
  kable_styling(bootstrap_options = c("hover"))
```


## Create a boxplot to visualise the difference between Entry Point and Operational levels of Residual Free Chlorine.

```{r}
p = data %>% 
  filter(`Sample class` == "Entry Point" | 
         `Sample class` == "Operational") %>%
  ggplot(aes(x = `Sample class`, 
             y = `Residual Free Chlorine (mg/L)`)) +
  geom_boxplot(fill = "lightblue", color = "darkblue") +
  labs(title = "Residual Free Chlorine (mg/L) for different sample classes") +
  theme_bw()

ggplotly(p)
```

## Which sample sites have the highest and lowest median readings for each chemical?

```{r}
site_medians_wide = data %>% 
  group_by(`Sample Site`) %>%
  summarise(med_chlorine = median(`Residual Free Chlorine (mg/L)`, na.rm = TRUE),
            med_turbidity = median(`Turbidity (NTU)`, na.rm = TRUE),
            med_fluoride = median(`Fluoride (mg/L)`, na.rm = TRUE)) 

# Tidy Way
site_medians_long = site_medians_wide %>%
  pivot_longer(!c(`Sample Site`),
               names_to = "Median Type",
               values_to = "Median Value")

max_min_median_sites = site_medians_long %>%
  group_by(`Median Type`) %>%
    summarise(
    Min_Val = min(`Median Value`, na.rm = TRUE),
    Min_Site = paste(`Sample Site`[which(`Median Value` == Min_Val)], 
                     collapse = ", "),
    Max_Val = max(`Median Value`, na.rm = TRUE),
    Max_Site = paste(`Sample Site`[which(`Median Value` == Max_Val)], 
                     collapse = ", ")
  )

max_min_median_sites %>%
  kable() %>%
  kable_styling(bootstrap_options = c("hover"))
  
# Non-Tidy Way -- copy code for each Median Type
# site_medians_wide %>%
#   select(`Sample Site`, med_turbidity) %>%
#   arrange(desc(med_turbidity)) %>%
#   filter(row_number() %in% c(1, n()))
# 
# site_medians_wide %>%
#   select(`Sample Site`, med_fluoride) %>%
#   arrange(desc(med_fluoride)) %>%
#   filter(row_number() %in% c(1, n()))
# 
# site_medians_wide %>%
#   select(`Sample Site`, med_chlorine) %>%
#   arrange(desc(med_chlorine)) %>%
#   filter(row_number() %in% c(1, n()))
```

## Visualise the difference in readings between the top and bottom sites for Turbidity in different ways. Can you find anything interesting about the sites?


```{r}
site_names = max_min_median_sites %>%
  filter(`Median Type` == "med_turbidity") %>%
  select(`Min_Site`, `Max_Site`) %>%
  t()

p = data %>% 
  filter(`Sample Site` %in% site_names) %>% 
  ggplot(aes(x = `Turbidity (NTU)`, fill = `Sample Site`)) +
    geom_histogram(bins = 30, color = "white") +
    scale_fill_manual(values = c("lightblue", "darkblue")) +
    theme_bw() +
    labs(y = "Frequency")

ggplotly(p)

p = data %>% 
  filter(`Sample Site` %in% site_names) %>% 
  ggplot(aes(x = `Sample Date`, y = `Turbidity (NTU)`, color = `Sample Site`))+
    geom_line() +
    scale_color_manual(values = c("lightblue", "darkblue")) +
    theme_bw()

ggplotly(p)
```


## How have the median readings for each of the chemicals changed over time?

```{r}
p = data %>% 
  
  group_by(`Sample Date`) %>%
  
  summarise(med_chlorine = median(`Residual Free Chlorine (mg/L)`, na.rm = TRUE),
            med_turbidity = median(`Turbidity (NTU)`, na.rm = TRUE),
            med_fluoride = median(`Fluoride (mg/L)`, na.rm = TRUE)) %>%
  
  pivot_longer(!c(`Sample Date`),
               names_to = "Median Type",
               values_to = "Median Value") %>%
  
  ggplot(aes(x = `Sample Date`, y = `Median Value`, colour = `Median Type`)) + 
    geom_line() +
    scale_color_manual(values = c("#ab5f54", "lightblue", "darkblue")) +
    theme_bw()

ggplotly(p)
```


## There seems to be seasonality trends in the data. Explore this.

```{r}
p = data %>% 
  group_by(Month) %>% 
  ggplot(aes(x = Month, y = log(`Turbidity (NTU)`))) +
  geom_boxplot(fill = "lightblue", color = "darkblue") +
  theme_bw() +
  theme(text = element_text(size = 10), 
        axis.text.x = element_text(angle = 45, vjust = -0.5)) +
  labs(y = "Log of Turbidity (NTU)")

ggplotly(p)
```


# Your Own Research Questions

What questions do you have about the data? Insert your analysis here.

## Executive Summary

This document sought to investigate the NYC Water Quality Monitoring dataset. Some initial issues were highlighted, including a lack of consistency in detail between measures presented in the report and the data itself. Exploratory data analysis revealed interesting patterns in the data and a variety of issues for further analysis, such as missing data, skew, and outliers. Preliminary investigation of the distribution of residual free chlorine by month over the whole dataset revealed that most months are somewhat roughly Gaussian, however, the distributions do appear leptykurtic (very high probability density in the middle) - as evidenced by the skinny distributions.

## Research Question: Is residual free chlorine normally distributed across months for the entire dataset?

```{r}
data %>%
  mutate(year = year(`Sample Date`)) %>%
  ggplot(aes(x = `Residual Free Chlorine (mg/L)`)) +
  geom_histogram(alpha = 0.9, fill = "steelblue2", binwidth = 0.01) +
  labs(title = "Distribution of residual free chlorine by month for 2019",
       x = "Residual Free Chlorine (mg/L)",
       y = "Frequency") +
  facet_wrap(~`Month Number`, scales = "free")
```





