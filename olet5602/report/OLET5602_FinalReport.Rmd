---
title: "OLET5602 Final Project: Transcription factor target gene prediction through multi-omics datasets"
author: "Trent Henderson"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Background and purpose

Transcriptional regulation orchestrates gene activity through the regulation of the DNA to RNA conversion process. This form of regulation is crucial to all living organisms. It is organised by transcription factors, who, along with other factors, in concert drive mRNA expression for an organism. These processes have wide-reaching, important implications, as distinct transcriptional networks drive development, lineage specification, and cell fate decisions during early embryonic development (Theunissen and Jaenisch, 2017). Recent advances in -omics technologies have made it possible to profile genome-wide transcriptional and epigenetic events for investigating transcriptional networks. As a result, a key goal of modern computational -omics work is to identify the target genes of transcription factors that drive key transcriptional events over a course of time. This report seeks to extend this goal by constructing a classification pipeline which uses -omics information (transcriptomics, proteomics, and epigenomics) to predict whether a target gene belongs to two important transcription factors (or not): SOX2 and NANOG. SOX2 is a key transcription factor for maintaining pluripotency (a cell's ability to differentiate into other cell types) of undifferentiated embryonic stem cells. NANOG also helps embryonic stem cells maintain pluripotency, but does so through the suppression of cell determination factors.

The following code excerpt loads the dataset and the relevant R packages to reproduce the work presented here (see end of the report for a full session information print out):

```{r, message = FALSE, warning = FALSE}
# Read in data and load R packages

load("Final_Project_ESC.RData", verbose = TRUE)
library(tibble)
library(dplyr)
library(tidyr)
library(purrr)
library(ggplot2)
library(ggrepel)
library(patchwork)
library(broom)
library(factoextra)
library(caret)
```

# Exploratory data analysis

XX use PCA

## Transcriptome

The transcriptome dataset contains $19,788$ unique genes, each sampled across 8 timepoints: 0hr (stem cells prior to differentiation stimulation), 1hr, 6hr, 12hr, 24hr, 36hr, 48hr, and 72hr. With such a large multivariate dataset, it is important to understand any relationships in the data, particularly in a lower dimensional space. As a preliminary analysis, we seek to understand whether there is visual distinction between the time points. The code below defines a reusable function for computing a pairwise correlation matrix between each timepoint, computing a principal components analysis (PCA) on the correlation matrix, and then plotting the projection of the PCA into two dimensions as a scatterplot. We can see a clear anti-clockwise trajectory of increasing time, with each positioned in its own region of space along this pattern. We also find that the first principal component (PC) explains $59.25\%$ of the variance in the correlation matrix data, while the second PC explains $31.61\%$, for a combined total of $90.68\%$ --- highlighting the dominance of these two PCs relative to the remaining six. As such, the dimensionality of the transcriptome dataset could be reduced substantially by using the PCs.

```{r, message = FALSE, warning = FALSE, fig.width = 6, fig.height = 4, fig.cap = "Low dimensional projection of transcriptome time-course differentation using PCA."}
#' Function to calculate PCA and return useful outputs for an input matrix
#' @param matrix the input data matrix
#' @param subtitle string for the plot subtitle. Defaults to \code{NULL} for no subtitle
#' @return an object of class \code{list}
#' @author Trent Henderson
#' 

do_pca <- function(matrix, subtitle = NULL){
  
  stopifnot(is.matrix(matrix))
  
  # Fit PCA on correlation matrix
  
  cors <- cor(matrix)
  fits <- stats::prcomp(cors, scale = TRUE)
  
  # Retrieve eigenvalues and tidy up variance explained for first 2 PCs for plotting
      
  eigens <- fits %>%
    tidy(matrix = "eigenvalues") %>%
    filter(PC %in% c(1, 2)) %>% # Filter to just the 2 going in the plot
    select(c(PC, percent)) %>%
    mutate(percent = paste0("(", round(percent * 100, digits = 2), "%)")) # Make nice format
  
  # Draw plot
        
  p <- fits %>%
    augment(cors) %>%
    mutate(.rownames = as.factor(.rownames),
           .rownames = gsub(".*_", "\\1", .rownames)) %>%
    ggplot(aes(x = .fittedPC1, y = .fittedPC2)) +
    geom_point(size = 3, ggplot2::aes(colour = .rownames)) +
    geom_text_repel(aes(label = .rownames)) +
    labs(x = paste0("PC 1 ", eigens$percent[1]),
         y = paste0("PC 2 ", eigens$percent[2]),
         caption = "Variance explained by each PC is shown in parentheses.") +
    scale_fill_brewer(palette = "Dark2") +
    theme_bw() +
    theme(legend.position = "none")
  
  if(!is.null(subtitle)){
    p <- p +
      labs(subtitle = subtitle,
           caption = NULL)
  }
  
  mylist <- list(fits, p)
  names(mylist) <- c("fits", "p")
  return(mylist)
}

# Run function

transcriptome_pca <- do_pca(matrix = Transcriptome)
print(transcriptome_pca$p)
```

## Proteome

X. Applying the function defined earlier for the transcriptome case, but with the proteome input data, we can again see a clear anti-clockwise trajectory of increasing time, with each positioned in its own region of space along this pattern. We also find that the first principal component (PC) explains a similarly large percentage of the variance in the correlation matrix data ($61.31\%$), while the second PC explains $26.44\%$, for a combined total of $87.75\%$ --- another strong result for just two PCs. This, again, suggests that the dimensionality of the proteome dataset could be reduced using PCs.

```{r, message = FALSE, warning = FALSE, fig.width = 6, fig.height = 4, fig.cap = "Low dimensional projection of proteome time-course differentation using PCA."}
proteome_pca <- do_pca(matrix = Proteome)
print(proteome_pca$p)
```

Evidently, time courses across both transcriptomic and proteomic structures appear to be differentiated in a low dimensional space of the first two PCs. However, it remains unclear whether each PC is driven by one or more time courses. Examining the variable loadings for the PCA can reveal this information, which is plotted below. Here, we see for both transcriptome and proteome, that multiple variables (i.e., time courses) contribute meaningfully to each principal component --- especially the first two which are of primary interest to us. This means that if further analysis uses PCs as inputs instead of the raw time course data, any model would not simply be learning on time courses that loaded singularly onto each PC. However, we do see that very strong loadings exist for the 48hr time course onto the second-last PCs in both cases (PC 7 for transcriptome and PC 6 for proteome), which is interesting. Further, we see the earliest (0hr for transcriptome, 1hr for proteome) and latest (72hr for both datasets) time courses exhibit very strong loading onto the final PC in both cases --- which potentially highlights the heterogeneity of these two time points relative to the rest. 

```{r, message = FALSE, warning = FALSE, fig.width = 11, fig.height = 8, fig.cap = "Variable loadings onto principal components for transcriptome and proteome datasets."}
#' Function to plot factor loadings for PCA
#' @param pca the model output object from \code{prcomp}
#' @param subtitle string specifying the subtitle of the plot
#' @return object of class \code{ggplot}
#' @author Trent Henderson
#' 

plot_loadings <- function(pca, subtitle){
  
  # Extract variable loadings
  
  contribs <- get_pca_var(pca)
  loadings_plot <- as.data.frame(contribs$contrib)
  n_vars <- ncol(loadings_plot)
  
  # Generate labels for plot programmatically
  
  fac_levs <- rep(NA, length.out = n_vars)
  
  for(i in 1:n_vars){
    fac_levs[i] <- paste0("PC ", i)
  }
  
  time_levs <- rownames(loadings_plot)
  
  # Draw plot
  
  loadings_plot <- loadings_plot %>%
    rownames_to_column(var = "timepoint") %>%
    pivot_longer(cols = 2:(n_vars + 1), names_to = "names", values_to = "value") %>%
    mutate(names = gsub("Dim.", "PC ", names)) %>%
    mutate(names = factor(names, levels = fac_levs),
           timepoint = factor(timepoint, levels = time_levs)) %>%
    ggplot(aes(x = names, y = timepoint, fill = value))  +
    geom_tile() +
    labs(subtitle = subtitle,
         x = "Principal component",
         y = "Variable",
         fill = "Component loading") +
    scale_fill_viridis_c(option = "plasma") +
    theme_bw() + 
    theme(axis.text.x = element_text(angle = 45, hjust = 1),
          axis.ticks.y = element_blank(),
          legend.position = "bottom",
          panel.grid.minor = element_blank())
  
  return(loadings_plot)
}

# Use functions to draw plots

transcriptome_load <- plot_loadings(pca = transcriptome_pca$fits, subtitle = "Transcriptome")
proteome_load <- plot_loadings(pca = proteome_pca$fits, subtitle = "Proteome")
patchwork::wrap_plots(transcriptome_load, proteome_load, ncol = 2, nrow = 1)
```

## Epigenome

The transcriptome and proteome data contained a single matrix each. However, for the epigenomics data, there are six different histone marks (H3K4me3, H3K27me3, Pol2, H3K4me1, H3K27ac, and H3K9me2), whose values are in a different scale for each one. With this in mind, we can perform the same analysis but separately for each histone mark. Similar results are found for the epigenome, with the first two PCs almost all the variance across all six histone marks, with notable results including the $82.4\%$ variance explained by PC 1 alone for H3K4me3, and the lowest variance explained by a PC 1 ($52.44\%$) for Pol2.

```{r, message = FALSE, warning = FALSE, fig.width = 12, fig.height = 8, fig.cap = "Low dimensional projection of epigenome time-course differentation using PCA."}
epigenome_list <- list(H3K27ac, H3K27me3, H3K4me1, H3K4me3, H3K9me2, PolII)
epi_names <- c("H3K27ac", "H3K27me3", "H3K4me1", "H3K4me3", "H3K9me2", "PolII")
names(epigenome_list) <- epi_names
epigenomes <- purrr::map2(.x = epigenome_list, .y = epi_names, ~ do_pca(matrix = .x, subtitle = .y))
plots <- list(epigenomes$H3K27ac$p, epigenomes$H3K27me3$p, epigenomes$H3K4me1$p, epigenomes$H3K4me3$p, epigenomes$H3K9me2$p, epigenomes$PolII$p)

patchwork::wrap_plots(plots, ncol = 3, nrow = 2) +
  patchwork::plot_annotation(caption = "Variance explained by each PC is shown in parentheses.")
```

We can similarly explore the variable loadings for the PCA models for the epigenome data. In the matrix of plots below, we see that across the six histone marks, the first two PCs are typically characterised by loadings from multiple time course variables --- suggesting their suitability as inputs for modelling. However, we do also see that very strong loadings of a single time course onto a range of PCs are visible, such as for H3K4me1, where 24hr loads strongly onto PC 2, 0hr onto PC 4, 1hr onto PC 7, and 72 hr onto PC 8.

```{r, message = FALSE, warning = FALSE, fig.width = 12, fig.height = 8, fig.cap = "Variable loadings onto principal components for epigenome datasets across six histone marks."}
epigenome_pc_list <- list(epigenomes$H3K27ac$fits, epigenomes$H3K27me3$fits, epigenomes$H3K4me1$fits, 
                          epigenomes$H3K4me3$fits, epigenomes$H3K9me2$fits, epigenomes$PolII$fits)

names(epigenome_list) <- epi_names
epigenome_loads <- purrr::map2(.x = epigenome_pc_list, .y = epi_names, ~ plot_loadings(pca = .x, subtitle = .y))
patchwork::wrap_plots(epigenome_loads, ncol = 3, nrow = 2)
```

## Construction of combined dataset

Prior work transformed both the transcriptome and proteome datasets to be in a comparable scale --- meaning they can be easily appended to form a combined dataset. We can combine the two based on only the consistent genes across both datasets:

```{r, message = FALSE, warning = FALSE}
Proteome2 <- as.data.frame(Proteome)
colnames(Proteome2) <- paste0("p_", colnames(Proteome2))
Proteome2 <- rownames_to_column(.data = Proteome2, var = "gene")
Transcriptome2 <- as.data.frame(Transcriptome)
colnames(Transcriptome2) <- paste0("t_", colnames(Transcriptome2))
Transcriptome2 <- rownames_to_column(.data = Transcriptome2, var = "gene")

prot_trans_df <- Proteome2 %>%
  inner_join(Transcriptome2, by = c("gene" = "gene")) %>% # Ensures we retain only common genes
  mutate(label = ifelse(gene %in% OSN_target_genes_subset, "OSN", "Other"),
         label = as.factor(label))
```

XX

```{r, message = FALSE, warning = FALSE, fig.width = 6, fig.height = 4, fig.cap = "Low dimensional projection of transcriptome and proteome time-course differentation using PCA by class, with OSN genes coloured in red (with covariance ellipse) and other genes coloured in green."}
# Visualise genes from both classes in low dimensional space

osn_pca <- stats::prcomp(prot_trans_df[, 2:16], scale = TRUE)

osn_pca_df <- osn_pca %>%
  augment(as.data.frame(prot_trans_df[, 2:16])) %>%
  dplyr::select(c(.fittedPC1:.fittedPC15)) %>%
  mutate(gene = prot_trans_df$gene,
         label = prot_trans_df$label)

osn_pca_eigens <- osn_pca %>%
  tidy(matrix = "eigenvalues") %>%
  filter(PC %in% c(1, 2)) %>% # Filter to just the 2 going in the plot
  select(c(PC, percent)) %>%
  mutate(percent = paste0("(", round(percent * 100, digits = 2), "%)")) # Make nice format

osn_pca_plot <- osn_pca_df %>%
  ggplot(aes(x = .fittedPC1, y = .fittedPC2)) +
  geom_point(data = subset(osn_pca_df, label == "Other"), size = 1, alpha = 0.8, colour = "#00BFC4") +
  stat_ellipse(data = subset(osn_pca_df, label == "OSN"), type = "norm", level = 0.99, geom = "polygon", alpha = 0.4, fill = "#F8766D") +
  geom_point(data = subset(osn_pca_df, label == "OSN"), size = 1, colour = "#F8766D") +
  labs(x = paste0("PC 1 ", osn_pca_eigens$percent[1]),
       y = paste0("PC 2 ", osn_pca_eigens$percent[2]),
       caption = "Variance explained by each PC is shown in parentheses.") +
  scale_fill_brewer(palette = "Dark2") +
  theme_bw() +
  theme(legend.position = "bottom")

print(osn_pca_plot)
```

Guided by the low dimensional projection presented in the above PCA plot, we can reduce the class imbalance through statistical selection of a sample of "Other" genes that are least like the OSN genes. The heuristic for this paper is that we will retain only those Other genes which lie outside the $99\%$ multivariate normal distribution covariance ellipse of the OSN genes in the two-dimensional space of $PC1$ and $PC2$. The below code finds these genes and highlights them in the space. This reduces the sample size of Other genes from $8260$ to $389$, which represents a shift in ratio of $OSN:Other$ genes of $95:8260$ to $95:389$ which is much more appropriate for statistical modelling.

```{r, message = FALSE, warning = FALSE, fig.width = 6, fig.height = 4, fig.cap = "Low dimensional projection of transcriptome and proteome time-course differentation using PCA by class, with OSN genes coloured in red (with covariance ellipse), other genes coloured in green, and the subset of other genes that are least like OSN genes as determined by positioning outside the covariance ellipse are coloured in purple."}
# Calculate mean and SD for first two PCs for "OSN" class

osn <- osn_pca_df[osn_pca_df$label == "OSN", c(".fittedPC1", ".fittedPC2")]
mu <- c(mean(osn$.fittedPC1, na.rm = TRUE), mean(osn$.fittedPC2, na.rm = TRUE))
sigma <- c(sd(osn$.fittedPC1, na.rm = TRUE), sd(osn$.fittedPC2, na.rm = TRUE))

# Find "Other" genes which are further than 1.96 * SD away from PC1 and PC2

coords <- ggplot_build(osn_pca_plot)$data
points <- coords[[1]]
ell <- coords[[2]]

other <- data.frame(points[1:2], 
                  in.ell = as.logical(sp::point.in.polygon(points$x, points$y, ell$x, ell$y))) %>%
  mutate(gene = subset(osn_pca_df, label == "Other")$gene) %>%
  filter(!in.ell) %>%
  pull(gene) # Retain "Other" genes that lie outside the covariance ellipse

# Subset original proteome/transcriptome dataset

prot_trans_df <- prot_trans_df %>%
  filter(gene %in% append(prot_trans_df[prot_trans_df$label == "OSN", 1], other))

# Filter and re-draw plot

osn_pca_plot_hl <- osn_pca_df %>%
  mutate(label = ifelse(label == "Other" & gene %in% other, "Subset", as.character(label)))

osn_pca_plot_hl <- osn_pca_plot_hl %>%
  ggplot(aes(x = .fittedPC1, y = .fittedPC2)) +
  geom_point(data = subset(osn_pca_plot_hl, label == "Other"), size = 1, alpha = 0.8, colour = "#00BFC4") +
  stat_ellipse(data = subset(osn_pca_plot_hl, label == "OSN"), type = "norm", level = 0.99, geom = "polygon", alpha = 0.4, fill = "#F8766D") +
  geom_point(data = subset(osn_pca_plot_hl, label == "OSN"), size = 1, colour = "#F8766D") +
  geom_point(data = subset(osn_pca_plot_hl, label == "Subset"), size = 1, colour = "#C77CFF") +
  labs(x = paste0("PC 1 ", osn_pca_eigens$percent[1]),
       y = paste0("PC 2 ", osn_pca_eigens$percent[2]),
       caption = "Variance explained by each PC is shown in parentheses.") +
  scale_fill_brewer(palette = "Dark2") +
  theme_bw() +
  theme(legend.position = "bottom")

print(osn_pca_plot_hl)
```

Preparation of the epigenome datasets according to the filtering of Other genes was also performed separately for each of the six histone marks:

```{r, message = FALSE, warning = FALSE}
#' Function to prepare histone mark data for modelling
#' 
#' @param X the data matrix
#' @return an object of class \code{data.frame}
#' @author Trent Henderson
#' 

prepare_histone_df <- function(X){
  
  X1 <- as.data.frame(X) %>%
  tibble::rownames_to_column(var = "gene") %>%
  mutate(label = ifelse(gene %in% OSN_target_genes_subset, "OSN", "Other"),
         label = as.factor(label)) %>%
  filter(gene %in% append(prot_trans_df[prot_trans_df$label == "OSN", 1], other))
  
  return(X1)
}

H3K27ac_df <- prepare_histone_df(H3K27ac)
H3K27me3_df <- prepare_histone_df(H3K27me3)
H3K4me1_df <- prepare_histone_df(H3K4me1)
H3K4me3_df <- prepare_histone_df(H3K4me3)
H3K9me2_df <- prepare_histone_df(H3K9me2)
PolII_df <- prepare_histone_df(PolII)
```

## Novel gene classification

Following exploratory data analysis, a set of seven predictive models for identifying gene membership to the two transcription factors of interest (SOX2 and NANOG) or not was constructed (one model for each dataset --- the combined proteome/transcriptome dataset and the six individual histone marks). The type of classification model that was chosen is a Gaussian process (GP) with a exponentiated-quadratic kernel/covariance function (also known as a "radial basis function" or "squared exponential"). Recall that a Gaussian distribution is parameterised by two scalar values: (i) mean $\mu$; and (ii) variance $\sigma^{2}$ (or the standard deviation which is the square root of the variance). We can write it as $\mathcal{N}(\mu, \sigma^{2})$. We can increase the dimensionality of this univariate case to describe *multivariate Gaussian distributions*, by increasing the dimensionality of the parameters. This results in the mean becoming a *mean vector* $\mu$ and the variance becoming a *covariance matrix* $\Sigma$ (as we now need to describe both the variance of each variable and the covariance between them), written as $\textbf{X} \sim \mathcal{N}(\mu, \Sigma)$. A GP is a generalisation of this idea to an infinite number of dimensions. This means the mean vector and covariance matrix now become a *mean function* $m(x)$ and *covariance function* $k(x, x')$ (also called a "kernel"). The most common covariance function is the exponentiated-quadratic, which we apply here. This function forms the basis for simpler kernel-based machine learning techniques, such as support vector machines. One of the reasons for its popularity is that it looks quite similar to the formula for a univariate Gaussian distribution. It is mathematically defined as:

$$
k(x, x') = \text{exp} \left( -\frac{1}{2\sigma^{2}}||x - x'||^{2} \right)
$$

where where $\sigma^{2}$ is the variance (average distance of a function away from its mean) and $\mathcal{l}$ is the lengthscale (the length of the "wiggles" in a function). These are *hyperparameters* that can be set or learnt to control the shape of the kernel. To implement this model in R, we make use of the `caret` package for machine learning which enables usage of an RBF GP through the model labelled `"gaussprRadial"`. Below, we define a function for training such a model using $10$-fold cross-validation, and run it for each of the seven datasets separately.

```{r, message = FALSE, warning = FALSE}
#' Do 10-fold CV to train a machine learning model
#' 
#' @param data \code{data.frame} of input data
#' @param model string of the \code{caret} model to use. Defaults to \code{"gaussprRadial"}
#' @param seed fix R's pseudo-random number generator for reproducibility. Defaults to \code{123}
#' @return object of class \code{list} containing \code{caret} model information
#' @author Trent Henderson
#' 

fit_model <- function(data, model = "gaussprRadial", seed = 123){
  
  set.seed(seed)
  
  # Remove "gene" column as it will mess with model
  
  data2 <- data %>%
    dplyr::select(-c(gene))
  
  # Fit model
  
  fit <- caret::train(label ~ .,
                      data = data2,
                      method = model,
                      trControl = caret::trainControl(method = "cv", number = 10, classProbs = TRUE),
                      preProcess = c("center", "scale"),
                      summaryFunction = twoClassSummary)
  
  return(fit)
}

# Run the function for all datasets

models <- list()
model_dfs <- list(prot_trans_df, H3K27ac_df, H3K27me3_df, H3K4me1_df, H3K4me3_df, H3K9me2_df, PolII_df)

for(i in 1:length(model_dfs)){
  themod <- fit_model(data = model_dfs[[i]], model = "gaussprRadial", seed = 123)
  models[[i]] <- themod
}

names(models) <- c("prot_trans_df", "H3K27ac_df", "H3K27me3_df", "H3K4me1_df", "H3K4me3_df", "H3K9me2_df", "PolII_df")
```

### Comparison to benchmark results

With the seven models now trained, we move to comparing predictive performance against benchmarks. The major comparison is the performance of each model in predicting gene class membership of the whole list of OSN target genes and not just the subset which formed the basis of the data to train each model. Performance can be quantified through different metrics obtained via calculations on the confusion matrix --- a matrix which cross-tabulates frequencies of model predictions against the actual class labels. The confusion matrix (for a two-class problem) returns four potential mutually-exclusive, collectively-exhaustive values: (i) true positive (TP); (ii) false positive (FP); (iii) false negative (FN); and (iv) true negative (TN). We summarise each model's predictive performance of the full gene set using four metrics calculated from the confusion matrix:

1. Accuracy --- $\frac{\text{TP} + \text{TN}}{\text{TP} + \text{FP} + \text{FN} + \text{TN}}$
3. Sensitivity --- $\frac{\text{TP}}{\text{TP} + \text{FN}}$
4. Specificity --- $\frac{TN}{\text{FP} + \text{TN}}$
2. Balanced Accuracy --- $\frac{\text{sensitivity} + \text{specificity}}{2}$

```{r, message = FALSE, warning = FALSE}

```

# SessionInfo

```{r}
sessionInfo()
```
